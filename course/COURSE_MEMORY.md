# CS 7180: Vibe Coding - Project Memory & Course Plan
## Complete Context for AI-Assisted Software Engineering Course

**Last Updated:** January 8, 2025  
**Course Start:** Spring 2026  
**Status:** Planning Phase - Course Design Complete

---

## 1. COURSE IDENTITY

### Basic Information
- **Course Code:** CS 7180: Special Topics in AI
- **Course Title:** Vibe Coding - AI-Assisted Software Engineering
- **Level:** Graduate (Master's)
- **Institution:** Northeastern University, Khoury College of Computer Sciences
- **Campus:** Oakland, California
- **Semester:** Spring 2026 (Inaugural Offering)
- **Schedule:** Tuesday/Thursday, 3:00PM-4:40PM PST
- **Location:** Lucie Stern 27, Oakland Campus
- **Prerequisites:** CS 5010 (min D) or CS 5004 (min C)
- **Instructor:** John Alexis Guerra Gomez
- **Email:** jguerra@northeastern.edu
- **Office Hours:** By appointment via Slack

### Course Mission
Train master's level CS students to become Silicon Valley-ready software engineers in the age of AI, mastering AI-assisted development tools while maintaining professional engineering standards.

### Unique Value Proposition
- **Only** graduate course teaching professional AI-assisted development workflows
- **Balances** AI speed with engineering quality (TDD, CI/CD, evals)
- **Portfolio-focused** - 3 production-ready applications
- **Validates fundamentals** - No-AI Challenge ensures understanding
- **Cutting-edge** - Covers parallel agentic programming, evals, advanced prompting

### Marketing Resources
- **Promotional Video:** https://www.youtube.com/shorts/GmMXaRY0Z-I
- **Target Audience:** Master's CS students seeking modern, practical development skills
- **Positioning:** "How software gets built in 2026" not theoretical CS

---

## 2. COURSE STRUCTURE & ASSESSMENT

### Assessment Breakdown
| Component | Weight | Details |
|-----------|--------|---------|
| **Participation** | 20% | 10% pre-class questions + 10% lottery points |
| **Homeworks** | 25% | 6 scaffolding assignments (4-5% each) |
| **Projects** | 55% | P1: 15%, P2: 20%, P3: 20% |
| **TOTAL** | 100% | Midterm No-AI Challenge (pass/fail, 60% required) |

### Participation Details
- **Pre-class Questions (10%):** Submit question + answer 2 peers before each class
  - 2 pts: Original, insightful question
  - 1 pt: Good question but duplicate
  - 0 pts: Low-effort question
  - Max 4 points per class (2 for question, 2 for answers)
  
- **Lottery (10%):** Random cold-calling in class
  - -1 pt: Absent or not paying attention
  - 0 pts: Wrong answer
  - 1 pt: Correct answer
  - 2 pts: Exceptional answer
  - Graded against class median (can go negative or above 100%)

- **Weekly Concept Checks:** Auto-graded Canvas quizzes
  - 5-10 questions, 10 minutes
  - Open 48 hours after lecture
  - Can take twice (higher score counts)
  - 14 total, drop lowest 2
  - Average of best 12 contributes to participation

### Grade Scale
- A: 93-100
- A-: 90-92
- B+: 86-89
- B: 82-85
- B-: 77-81
- C+: 73-76
- C: 69-72
- C-: 65-68
- F: 0-59

### Late Policy
- **Homeworks:** 10% off per day (max 3 days)
- **Projects:** 5% off per day (max 5 days)
- **Weekly quizzes:** Cannot be made up (2 lowest dropped)
- **Extensions:** Available with 48-hour notice and valid reason

---

## 3. WEEKLY SCHEDULE (15 Weeks)

| Week | Module | Topics | Deliverables | Project Status |
|------|--------|--------|--------------|----------------|
| **1** | **Foundations** | â€¢ Course intro & portfolio planning<br>â€¢ Mom Test introduction<br>â€¢ Design Thinking basics<br>â€¢ **LLM Fundamentals (2 hours)**<br>&nbsp;&nbsp;- Transformers, tokens, context windows<br>&nbsp;&nbsp;- Hallucinations, temperature<br>&nbsp;&nbsp;- Model comparison (GPT/Claude/Gemini) | Weekly Quiz 1<br>Pre-class questions | **P1:** Ideation<br>Problem identification |
| **2** | **Modality 1** | â€¢ Claude Web & Projects<br>â€¢ Artifacts & conversational coding<br>â€¢ Architecture planning with AI<br>â€¢ Requirements gathering workshop<br>â€¢ User story writing | **HW1 DUE:** Mom Test<br>Weekly Quiz 2 | **P1:** User research<br>PRD & user stories |
| **3** | **Prompt Engineering** | â€¢ Effective prompt structure<br>â€¢ Few-shot learning<br>â€¢ System vs user prompts<br>â€¢ Iteration strategies<br>â€¢ Hands-on workshop | **HW2 DUE:** Prompts<br>Weekly Quiz 3 | **P1:** Architecture<br>Begin prototyping |
| **4** | **Modality 2 (Part 1)** | â€¢ Antigravity installation & setup<br>â€¢ Tab autocomplete<br>â€¢ Inline chat (Cmd+K)<br>â€¢ @ context references<br>â€¢ Basic .antigravityrules<br>â€¢ **TDD Introduction** | Weekly Quiz 4 | **P1:** Sprint 1<br>Implementation begins |
| **5** | **Antigravity + CI/CD** | â€¢ Composer (multi-file)<br>â€¢ Advanced .antigravityrules<br>â€¢ **CI/CD Fundamentals**<br>&nbsp;&nbsp;- GitHub Actions basics<br>&nbsp;&nbsp;- Test automation<br>â€¢ Setting up first pipeline | Weekly Quiz 5 | **P1:** Sprint 2<br>Add CI pipeline |
| **6** | **Project 1 + Modality 3** | â€¢ **PROJECT 1 PRESENTATIONS**<br>â€¢ Claude Code & Terminal AI<br>â€¢ Agentic coding intro<br>â€¢ Terminal workflows<br>â€¢ Automation & scripts | **PROJECT 1 DUE** ðŸŽ¯<br>Weekly Quiz 6 | **P1:** Final submission<br>**P2:** Planning begins |
| **7** | **Advanced Prompting** | â€¢ Chain-of-thought<br>â€¢ Meta-prompting<br>â€¢ Prompt chaining<br>â€¢ Structured prompts (XML/JSON)<br>â€¢ Cost optimization<br>â€¢ Building prompt libraries | **HW3 DUE:** Context<br>Weekly Quiz 7 | **P2:** Sprint 1<br>Architecture & setup |
| **8** | **Context Engineering** | â€¢ Context windows<br>â€¢ Context sources & optimization<br>â€¢ RAG for code<br>â€¢ Token management<br>â€¢ .antigravityrules best practices<br>â€¢ MCPs (Model Control Protocols) | Weekly Quiz 8 | **P2:** Sprint 2<br>Core features |
| **9** | **Evals Part 1** | â€¢ What are evals & why they matter<br>â€¢ Types of evals:<br>&nbsp;&nbsp;- Correctness<br>&nbsp;&nbsp;- Quality<br>&nbsp;&nbsp;- Semantic<br>â€¢ Building eval frameworks<br>â€¢ Golden dataset creation | Weekly Quiz 9 | **P2:** Sprint 3<br>Testing & quality |
| **10** | **TDD + CI/CD + Evals** | â€¢ Advanced TDD with AI<br>â€¢ Multi-stage CI/CD pipelines<br>â€¢ Deploy previews<br>â€¢ Coverage reporting<br>â€¢ Security scanning<br>â€¢ **Evals Part 2:**<br>&nbsp;&nbsp;- LLM-as-judge<br>&nbsp;&nbsp;- Automated dashboards | **HW4 DUE:** TDD+CI/CD<br>**MIDTERM:** No-AI Challenge<br>Weekly Quiz 10 | **P2:** Final polish<br>Complete eval suite |
| **11** | **Project 2 + Agile** | â€¢ **PROJECT 2 PRESENTATIONS**<br>â€¢ Agile workflows with AI<br>â€¢ Scrum ceremonies<br>â€¢ Sprint planning with AI<br>â€¢ Team velocity & estimation<br>â€¢ **Team Formation Workshop** | **PROJECT 2 DUE** ðŸŽ¯<br>Weekly Quiz 11 | **P2:** Final submission<br>**P3:** Team formation |
| **12** | **Parallel Agents** | â€¢ Agent fundamentals<br>&nbsp;&nbsp;- ReAct, Plan-and-Execute<br>&nbsp;&nbsp;- Agent architectures<br>â€¢ Single agent workflows<br>â€¢ Multi-agent coordination<br>â€¢ Agent safety & debugging<br>â€¢ Cost control for agents | **HW5 DUE:** Parallel agents<br>Weekly Quiz 12 | **P3:** Sprint 1<br>Parallel development |
| **13** | **Advanced Patterns** | â€¢ System design with AI<br>â€¢ Advanced CI/CD:<br>&nbsp;&nbsp;- Multi-environment<br>&nbsp;&nbsp;- Canary deployments<br>&nbsp;&nbsp;- Blue-green deployments<br>â€¢ Performance gates<br>â€¢ Database optimization<br>â€¢ API design best practices | **HW6 DUE:** Production<br>Weekly Quiz 13 | **P3:** Sprint 2<br>Advanced features |
| **14** | **Production** | â€¢ Monitoring & observability<br>â€¢ Error tracking & logging<br>â€¢ Performance optimization<br>â€¢ Security best practices<br>â€¢ Accessibility (WCAG basics)<br>â€¢ Professional documentation<br>â€¢ Portfolio building tips | Weekly Quiz 14 | **P3:** Sprint 3<br>Polish & deploy |
| **15** | **Demo Day** | â€¢ **FINAL PRESENTATIONS**<br>â€¢ Portfolio showcase<br>â€¢ Course retrospective<br>â€¢ Industry panel (optional)<br>â€¢ Career prep discussion | **PROJECT 3 DUE** ðŸŽ¯ | **P3:** Final demos<br>Portfolio complete |

---

## 4. THE THREE MODALITIES

### Modality 1: Claude Web Interface (Week 2)
**Best for:** Architecture planning, learning, complex problem-solving, brainstorming

**Skills Covered:**
- Using Claude Projects for context management
- Creating artifacts for prototyping
- Conversational iteration
- Architecture discussions
- Understanding limitations

**Lab Exercise:** Build a simple feature entirely through Claude Web

**When to Use:**
- Planning system architecture
- Learning new concepts
- Debugging complex logic
- Brainstorming solutions
- Creating documentation

---

### Modality 2: Antigravity IDE (Weeks 4-5)
**Best for:** Professional development, production code, daily coding workflow

**Skills Covered:**
- Tab autocomplete
- Inline chat (Cmd+K)
- Composer for multi-file changes
- @ context references (@file, @docs, @codebase)
- .antigravityrules configuration
- YOLO mode for autonomous testing
- Diff review and acceptance

**Lab Exercise:** Contribute to existing codebase using Antigravity

**When to Use:**
- Daily development work
- Implementing features
- Refactoring code
- Writing tests
- Working with large codebases

---

### Modality 3: Claude Code / Terminal AI (Week 6)
**Best for:** Automation, multi-file refactoring, DevOps, complex migrations

**Skills Covered:**
- Terminal-based workflows
- Autonomous multi-file changes
- Setting agent boundaries
- Monitoring autonomous actions
- Script automation
- When agents vs. interactive tools

**Lab Exercise:** Use Claude Code to refactor a legacy codebase

**When to Use:**
- Large-scale refactoring
- DevOps automation
- Database migrations
- Setting up CI/CD
- Infrastructure as code

---

## 5. PROJECTS (55% of Grade)

### Project 1: Personal Utility App (15%) - Due Week 6

**Objective:** Master one AI modality while building a real solution

**Requirements:**
- **Functional:**
  - Solves validated real problem (Mom Test)
  - 5+ user stories with CRUD operations
  - Data persistence
  - Responsive design (mobile + desktop)
  
- **Technical:**
  - ONE primary modality focus
  - JavaScript/TypeScript
  - Simple tech stack (vanilla JS or React)
  - 50%+ test coverage
  - GitHub Actions CI pipeline (lint + test + deploy)
  - Deployed and publicly accessible

- **Documentation:**
  - README (problem, solution, setup, tech stack, AI usage)
  - User stories document
  - 5-minute demo video
  - 500-word reflection

**Deliverables:**
1. GitHub repository
2. Deployed app URL
3. Demo video (YouTube/Loom)
4. Reflection document

**Rubric (150 points):**
- Functionality: 40 pts
- Technical Implementation: 40 pts
- AI Usage: 30 pts
- Documentation: 25 pts
- Process: 15 pts

---

### Project 2: Full-Stack Application (20%) - Due Week 11

**Objective:** Integrate multiple modalities with professional practices

**Requirements:**
- **Functional:**
  - Complete full-stack (frontend + backend + database)
  - User authentication (JWT or OAuth)
  - 3+ distinct features/roles
  - Real-time updates OR complex state management
  - Public API with documentation
  - Professional UI/UX

- **Technical:**
  - Use all 3 modalities appropriately
  - Tech stack:
    - Frontend: React/Next.js + TailwindCSS
    - Backend: Node.js/Express OR Next.js API routes
    - Database: PostgreSQL or MongoDB
    - Auth: JWT or OAuth
  - **Test-Driven Development:**
    - 80%+ coverage
    - Unit + Integration + E2E tests (Playwright/Cypress)
  - **Evaluation Suite:**
    - Automated test runs
    - Code quality metrics
    - Security scanning
    - Performance benchmarks
    - Custom semantic evals
    - Eval dashboard
  - **Advanced CI/CD:**
    - Multi-stage pipeline
    - Deploy previews for PRs
    - Coverage reporting (CodeCov)
    - Security scanning in CI
    - Automated deployment
    - Environment management

- **Agile Process:**
  - 2+ documented sprints
  - Sprint planning documents
  - Daily standup notes
  - Sprint retrospectives
  - User stories with acceptance criteria
  - Task estimation

- **Documentation:**
  - Comprehensive README
  - API documentation (OpenAPI/Swagger)
  - Architecture diagram
  - Database schema diagram
  - Setup/deployment guide
  - Sprint retrospectives
  - 10-minute demo video
  - 1500-word technical blog post

**Deliverables:**
1. GitHub repository
2. Deployed app (production URL)
3. Eval dashboard (live or screenshots)
4. Complete documentation package
5. Demo video
6. Technical blog post

**Rubric (200 points):**
- Functionality: 45 pts
- Technical Excellence: 60 pts
- AI Mastery: 30 pts
- CI/CD & DevOps: 30 pts
- Agile Process: 20 pts
- Documentation: 15 pts

---

### Project 3: Team Application with Advanced AI (20%) - Due Week 15

**Objective:** Build production-grade application with advanced techniques

**Requirements:**
- **Functional:**
  - Complex, production-ready application
  - Multiple user types with different capabilities
  - Advanced features requiring sophisticated logic
  - Real-world use case (Mom Test validated)
  - Portfolio/interview-worthy quality

- **Technical:**
  - **Advanced Architecture:**
    - Microservices OR well-architected monolith
    - Message queues or event-driven (if appropriate)
    - Caching strategy (Redis or similar)
    - API gateway or similar
  
  - **Parallel Agentic Programming:**
    - 3+ features built with parallel agents
    - Clear agent coordination strategy
    - Documentation of agent workflow
  
  - **Comprehensive Evaluation System:**
    - Multi-dimensional evals (correctness, quality, semantics, performance, security)
    - LLM-as-judge implementation
    - Historical metrics tracking
    - Golden dataset of test cases
    - Quantitative comparison of AI approaches
  
  - **Enterprise CI/CD:**
    - Multi-environment (dev/staging/prod)
    - Advanced deployment (canary OR blue-green)
    - Performance gates (Lighthouse, bundle size)
    - Automated security scanning (SAST/DAST)
    - Database migrations in pipeline
    - Automated rollback capability
  
  - **Production Monitoring:**
    - Error tracking (Sentry or similar)
    - Performance monitoring (APM)
    - Uptime monitoring
    - Log aggregation
    - Alerting system
  
  - **Security:**
    - Security audit passed
    - Penetration testing performed
    - OWASP top 10 addressed
    - Secrets management
    - Rate limiting

- **Team Process:**
  - 3+ sprints documented
  - Team contract established
  - Daily standups recorded
  - Sprint planning & retrospectives
  - Code review process
  - Pair programming sessions
  - Clear Git workflow (branches, PRs, reviews)
  - Peer evaluations

- **Documentation:**
  - System architecture documentation
  - API documentation (comprehensive)
  - Database schema + ER diagrams
  - Deployment guide
  - Developer onboarding guide
  - User guide
  - All sprint retrospectives
  - Team retrospective
  - Individual reflections (each member)
  - Technical blog post (team effort)
  - 20-minute demo presentation

**Deliverables:**
1. GitHub organization with repositories
2. Deployed application (production)
3. Monitoring dashboard access
4. Eval system with historical data
5. Complete documentation package
6. Team presentation
7. Individual reflections
8. Technical blog post

**Rubric (200 points):**
- Application Quality: 50 pts
- Advanced AI Techniques: 45 pts
- Technical Excellence: 40 pts
- CI/CD & DevOps: 30 pts
- Team Collaboration: 20 pts
- Documentation: 15 pts

**Note:** Individual grades adjusted by peer evaluations (Â±10%)

---

## 6. HOMEWORK ASSIGNMENTS (25% of Grade)

### HW1: Mom Test Interviews + User Stories (Week 2) - 4%

**Objective:** Learn to validate ideas through proper user research

**Tasks:**
1. Identify personal problem worth solving (for Project 1)
2. Conduct 3 "Mom Test" interviews with potential users
3. Write interview summaries (anonymized)
4. Create 5-8 user stories based on findings
5. Prioritize using MoSCoW method
6. Write initial PRD (1-2 pages)

**Deliverables:**
- Interview notes document
- User stories (proper format)
- Prioritization with justification
- PRD draft

**Rubric (40 points):**
- Interview quality: 40%
- User stories: 30%
- PRD quality: 20%
- Reflection: 10%

---

### HW2: Prompt Engineering Battle (Week 3) - 4%

**Objective:** Master effective prompting through iteration

**Challenges:**
1. **Easy:** Email validation function with regex
2. **Medium:** React sortable/filterable data table with pagination
3. **Hard:** Caching layer with TTL, LRU eviction, persistence

**For Each Challenge:**
- Write initial prompt (v1)
- Generate code and test
- Iterate and improve prompt (v2, v3, etc.)
- Document what made prompts better
- Compare code quality across versions

**Deliverables:**
- Prompt versions document (all iterations)
- Generated code from each version
- Test results for each version
- 500-word reflection: "What makes a great prompt?"
- Personal prompt template developed

**Rubric (40 points):**
- Prompt quality: 40%
- Code quality: 30%
- Iteration process: 20%
- Reflection depth: 10%

---

### HW3: Context Engineering Lab (Week 7) - 4%

**Objective:** Learn to optimize AI context for better code generation

**Provided:** Messy codebase (~20 files, various patterns)

**Tasks:**
1. **Analyze codebase:**
   - Identify coding patterns and conventions
   - Document architecture decisions
   - Note inconsistencies

2. **Create `.antigravityrules` file:**
   - Coding standards
   - Architecture patterns
   - Naming conventions
   - Do's and don'ts
   - Technology stack guidelines

3. **Test context:**
   - Add feature WITHOUT rules
   - Add same feature WITH rules
   - Compare quality

4. **Optimize:**
   - Refine rules based on results
   - Test again
   - Document improvements

**Deliverables:**
- Codebase analysis document
- `.antigravityrules` file (well-commented)
- Before/after code comparison
- 2-3 page report: "How context engineering improved results"
- Best practices guide for context optimization

**Rubric (40 points):**
- Analysis quality: 25%
- .antigravityrules effectiveness: 35%
- Before/after comparison: 25%
- Documentation: 15%

---

### HW4: TDD + CI/CD + Evals Suite (Week 9-10) - 5%

**Objective:** Build comprehensive quality assurance system

**Part 1: Test-Driven Development (20%)**
Build new feature using strict TDD:
1. Write failing tests
2. Use AI to implement minimum code to pass
3. Refactor
4. Repeat for all acceptance criteria

**Part 2: Evaluation Suite (35%)**
Create comprehensive evals:
- Unit tests (80%+ coverage)
- Integration tests
- E2E tests (Playwright/Cypress)
- Linting (ESLint/Prettier)
- Type checking (TypeScript)
- Security scanning (npm audit)
- Performance benchmarks
- At least 1 custom semantic eval

**Part 3: CI/CD Pipeline (35%)**
Set up complete pipeline:
1. Quality Checks (lint, format, types)
2. Security Audit
3. Unit Tests (with coverage)
4. Integration Tests
5. E2E Tests
6. Build
7. Deploy Preview (on PR)
8. Deploy Production (on merge)

**Part 4: Eval Dashboard (10%)**
Create dashboard showing:
- Test results
- Coverage trends
- Performance metrics
- Security scan results
- Build success rate

**Deliverables:**
- Feature code (tests written first)
- Complete eval suite (runnable)
- Working CI/CD pipeline
- Eval dashboard or report
- Documentation: "My TDD + CI/CD + Evals Guide"

**Rubric (50 points):**
- TDD process: 20%
- Eval comprehensiveness: 35%
- CI/CD implementation: 30%
- Dashboard quality: 10%
- Documentation: 5%

---

### HW5: Parallel Agent Orchestration (Week 12) - 4%

**Objective:** Master coordinating multiple AI agents for complex tasks

**Example Feature:** "Add OAuth authentication with Google and GitHub"

**Phase 1: Planning (20%)**
- Break feature into independent tasks
- Assign tasks to different "agents" (A, B, C, D)
- Define interfaces between components
- Create coordination strategy

**Phase 2: Parallel Execution (40%)**
- Agent A: Database schema + migrations
- Agent B: Backend API endpoints
- Agent C: Frontend components
- Agent D: Comprehensive test suite

Run agents simultaneously using:
- Multiple Antigravity sessions, OR
- Multiple Claude Code instances, OR
- Different tools for different agents

**Phase 3: Integration (30%)**
- Merge agent outputs
- Resolve conflicts
- Ensure consistency
- Test integrated system

**Phase 4: Retrospective (10%)**
- What worked well?
- What was challenging?
- How would you improve?

**Deliverables:**
- Task breakdown document
- Prompts used for each agent
- Integration strategy
- Git history showing parallel work
- Working integrated feature
- Retrospective document with lessons learned

**Rubric (40 points):**
- Planning quality: 20%
- Parallel execution: 40%
- Integration success: 25%
- Retrospective: 15%

---

### HW6: Production Readiness Checklist (Week 13) - 4%

**Objective:** Transform any app into production-grade software

**Provided:** Working application (can be your own or provided)

**Tasks:**

**1. Security Audit (25%)**
- Fix all vulnerabilities
- Add proper authentication
- Input validation everywhere
- Environment variables for secrets
- Rate limiting
- HTTPS enforcement
- Security headers (CSP, etc.)

**2. Performance Optimization (25%)**
- Database indexing
- Query optimization
- Caching strategy (Redis/in-memory)
- Code splitting / lazy loading
- Image optimization
- Bundle size optimization
- Load testing results

**3. Monitoring & Observability (25%)**
- Error tracking (Sentry or similar)
- Analytics
- Health checks
- Logging strategy
- Uptime monitoring
- Performance monitoring

**4. CI/CD Enhancement (15%)**
- Multi-environment pipeline (dev/staging/prod)
- Performance gates
- Automated security scanning
- Rollback capability
- Blue-green OR canary deployment

**5. Documentation (10%)**
- README with setup
- API documentation
- Architecture diagram
- Deployment guide
- Runbook for incidents

**Deliverables:**
- Before/after comparison document
- Completed production readiness checklist
- Deployed application with monitoring
- Documentation package
- Guide: "How I Made It Production-Ready"

**Rubric (40 points):**
- Security: 25%
- Performance: 25%
- Monitoring: 25%
- CI/CD: 15%
- Documentation: 10%

---

## 7. KEY COURSE FEATURES

### LLM Fundamentals Module (Week 1)
**Duration:** 2 hours  
**Critical Foundation:** Understanding before using

**Topics Covered:**
1. **How Transformers Work (High-Level)**
   - Attention mechanism
   - Self-attention
   - Multi-head attention
   - Why transformers revolutionized NLP

2. **Tokens, Context Windows, Temperature**
   - What is a token?
   - Token limits (Claude: 200K, GPT-4: 128K, etc.)
   - How temperature affects randomness
   - Top-p (nucleus) sampling

3. **Why Hallucinations Occur**
   - Probabilistic text generation
   - Training data limitations
   - Confidence vs. correctness
   - How to detect hallucinations

4. **Model Comparison**
   - GPT-4: Strengths and weaknesses
   - Claude: Strengths and weaknesses
   - Gemini: Strengths and weaknesses
   - When to use which model

5. **When to Trust AI Outputs**
   - Verification strategies
   - Cross-referencing
   - Testing generated code
   - Human-in-the-loop workflows

**Pedagogy:**
- Interactive demonstrations
- Live model comparisons
- Hallucination examples
- Group discussions

---

### Midterm: No-AI Challenge (Week 10)
**Duration:** 90 minutes in-class  
**Format:** Coding exam without ANY AI tools

**Purpose:**
- Ensure students can code independently
- Validate understanding of fundamentals
- Prevent over-reliance on AI
- Build confidence

**Rules:**
- No AI tools (Copilot, Claude, ChatGPT, etc.)
- Can use documentation (MDN, official docs)
- Can use Stack Overflow for reference
- Must write code from scratch

**Content:** 3-4 coding problems testing:
- JavaScript/TypeScript fundamentals
- Data structures & algorithms (basic)
- Async programming (promises, async/await)
- DOM manipulation OR React basics
- API calls
- Error handling

**Example Problems:**

**Problem 1 (Easy - 25%):**
```javascript
// Fetch user data from API and return only admin users
// Handle errors appropriately
async function getAdminUsers(apiUrl) {
  // Your code here
}
```

**Problem 2 (Medium - 35%):**
```javascript
// Implement debounce function
// Delays execution until wait time elapsed since last call
function debounce(func, wait) {
  // Your code here
}
```

**Problem 3 (Medium-Hard - 40%):**
```javascript
// Build React component that:
// 1. Fetches data from API
// 2. Displays in list with filtering
// 3. Handles loading/error states
// 4. Proper TypeScript types
const DataList: React.FC<Props> = () => {
  // Your code here
}
```

**Grading:**
- Functionality: 60%
- Code quality: 25%
- Error handling: 15%

**Scoring:**
- Not part of 100% (doesn't affect letter grade)
- Must score 60%+ to pass
- Fail â†’ meeting with instructor, possible grade cap
- Results factor into participation score

**Preparation:**
- Practice problems posted 2 weeks before
- Review session offered
- Office hours available
- Study guide provided

---

### Evaluation-Driven Development (Evals)
**Innovation:** Systematic quality measurement for AI code

**Why Evals Matter:**
- AI code quality varies widely
- Need objective measurement
- Professional practice in top companies
- Enables continuous improvement

**Types of Evals:**

1. **Correctness Evals**
   - Does code work as intended?
   - Passes all test cases?
   - Edge cases handled?

2. **Quality Evals**
   - Code maintainability
   - Readability
   - Follows best practices
   - Proper error handling

3. **Semantic Evals**
   - Intent preserved?
   - Business logic correct?
   - User experience maintained?

4. **Performance Evals**
   - Execution speed
   - Memory usage
   - Scalability
   - Load testing

5. **Security Evals**
   - Vulnerability scanning
   - Input validation
   - Authentication/authorization
   - OWASP compliance

**LLM-as-Judge Technique:**
- Use LLM to evaluate AI-generated code
- Structured evaluation criteria
- Quantitative scoring
- Automated feedback

**Golden Dataset:**
- Collection of verified test cases
- Known correct outputs
- Edge cases covered
- Used for benchmarking

**Eval Dashboard:**
- Visual representation of quality metrics
- Trends over time
- Comparison across prompts
- Identifies areas for improvement

**Framework Example:**
```
1. Define metrics â†’ 
2. Create golden dataset â†’ 
3. Run baseline â†’ 
4. Compare variations â†’ 
5. Iterate â†’ 
6. Track over time
```

---

## 8. REQUIRED MATERIALS

### Books (Required)
1. **The Mom Test** by Rob Fitzpatrick
   - ISBN: 978-1492180746
   - Used: Weeks 1-2
   - Focus: Customer validation, requirements gathering

2. **Designing for Growth** by Jeanne Liedtka & Tim Ogilvie
   - ISBN: 978-0231158930
   - Used: Weeks 1-3
   - Focus: Design thinking toolkit

3. **Scrum** by Jeff Sutherland
   - ISBN: 978-0385346450
   - Used: Weeks 10-12
   - Focus: Agile methodologies

### Online Documentation (Required)
- Anthropic Claude Documentation: https://docs.anthropic.com
- Antigravity Documentation: https://antigravity.dev/docs
- GitHub Copilot Guide: https://docs.github.com/copilot

### Tools (Required)
**Paid Subscriptions (~$40/month total):**
- Antigravity IDE: ~$20/month
- Claude.ai Pro: $20/month

**Free Tools:**
- GitHub account (Pro for students)
- Node.js 18+ and npm
- Git installed locally

**Recommended Tools:**
- Claude Code (agentic terminal tool)
- Postman or Insomnia (API testing)
- Sentry (error tracking - free tier)
- Vercel / Railway / Render (deployment)
- CodeCov (coverage reporting)

### Technology Stack

**Primary Languages:**
- JavaScript (ES6+)
- TypeScript

**Frontend:**
- React 18+
- Next.js 14+
- TailwindCSS
- shadcn/ui (optional)

**Backend:**
- Node.js 18+
- Express OR Next.js API routes
- RESTful API design

**Databases:**
- PostgreSQL (recommended)
- MongoDB (alternative)
- Prisma ORM

**Authentication:**
- JWT tokens
- OAuth 2.0 (Google, GitHub)

**Testing:**
- Jest or Vitest (unit tests)
- Playwright or Cypress (E2E tests)
- React Testing Library

**CI/CD:**
- GitHub Actions
- Vercel / Railway / Render

**DevOps:**
- Docker (optional)
- GitHub
- Environment variables

---

## 9. COMMUNICATION & RESOURCES

### Primary Channels

**Slack (Main Communication)**
Workspace: [Link provided in Canvas]

Channels:
- `#general` - General questions
- `#projects` - Project help and approval (ALL projects need approval)
- `#resources` - Shared tools, articles, prompts
- `#announcements` - Official announcements (TA/Prof only)
- `#random` - Off-topic, memes, community
- `#classchat` - Class discussion topics

**Canvas**
- Assignment submissions
- Grades
- Weekly quizzes
- Official course materials

**Office Hours**
- Instructor: Tuesdays 2-4PM (Carnegie 201)
- On-demand via Slack
- TA hours (posted on Slack)

### Support Resources

**Getting Help (Priority Order):**
1. Try debugging yourself (read error messages!)
2. Ask AI for help (document the process)
3. Check documentation
4. Search Slack history
5. Ask peers on Slack
6. Come to office hours
7. Schedule meeting with instructor

**When Stuck:**
- Don't wait until deadline
- Ask early and often
- Share your thought process
- Show what you've tried

**AI Debugging Clinics:**
- Friday drop-in sessions
- Bring your AI-related problems
- Learn from others' issues
- Community troubleshooting

---

## 10. ACADEMIC POLICIES

### Academic Integrity with AI

**This course REQUIRES AI tool use** but with strict rules:

**Must Do:**
- Document all AI tool usage
- Understand all code submitted
- Attribute AI-generated code (>3 lines)
- Pass No-AI Challenge (proves understanding)

**Cannot Do:**
- Submit code you don't understand
- Copy from other students
- Share project code during semester
- Use previous semester's solutions

**Attribution Format:**
```javascript
// Generated by Claude 3.5 Sonnet with prompt:
// "Create a function that validates email addresses"
// Modified: Added edge case handling for plus addressing
function validateEmail(email) {
  // ... code ...
}
```

**Violations:**
- First offense: Zero on assignment + meeting
- Second offense: F in course + dean's report
- Academic dishonesty report to university

### Accommodations

**Students with Disabilities:**
- Contact Disability Resource Center: (844) 688-6287
- Provide DRC letter early in semester
- Accommodations arranged privately

**Other Accommodations:**
- Medical emergencies
- Religious observances
- University-approved absences
- Family emergencies

Request accommodations 48 hours in advance when possible.

### Title IX

Faculty are mandatory reporters for Title IX. Confidential resources:
- University Health and Counseling Services (UHCS)
- Sexual Violence Resource Center (SVRC)

Report concerns: titleix@northeastern.edu or NUPD (844) 688-6287

### Classroom Environment

**Expected Behavior:**
- Respectful discourse
- Active listening
- Professional conduct
- Constructive feedback
- Intellectual curiosity

**Unacceptable:**
- Harassment
- Discrimination
- Disruptive behavior
- Unprofessional conduct

Repeated violations â†’ grade consequences

---

## 11. COURSE OUTCOMES & CAREER READINESS

### Portfolio Deliverables

By course end, students will have:

**3 Production Apps:**
1. Personal Utility App (deployable, resume-worthy)
2. Full-Stack Application (advanced features)
3. Team Application (enterprise-grade)

**Professional Presence:**
- GitHub profile with quality projects
- Technical blog posts (2+)
- Demo videos (3)
- Comprehensive documentation
- Public APIs with docs

**Artifacts:**
- Detailed project READMEs
- Architecture diagrams
- API documentation
- Deployment guides
- Sprint retrospectives

### Technical Skills

**AI Mastery:**
- Expert Claude Web usage
- Professional Antigravity workflows
- Autonomous agent orchestration
- Advanced prompt engineering
- Context optimization
- Eval-driven development

**Engineering Practices:**
- Test-Driven Development
- CI/CD pipeline design
- Agile/Scrum methodologies
- Code review processes
- Git workflows
- Production deployment

**Full-Stack Development:**
- React/Next.js applications
- Node.js backend services
- Database design & optimization
- RESTful API design
- Authentication/authorization
- State management

**Professional Standards:**
- Code quality & maintainability
- Security best practices
- Performance optimization
- Monitoring & observability
- Documentation
- Team collaboration

### Knowledge Base

**LLM Understanding:**
- How transformers work
- Token limits & context windows
- Temperature & sampling
- Hallucination causes
- Model selection criteria

**Software Engineering:**
- System design basics
- Architecture patterns
- Scalability considerations
- Security principles
- Performance optimization

**Modern Workflows:**
- AI-assisted development
- Automated testing
- Continuous integration
- Deployment strategies
- Production monitoring

### Career Preparation

**Job-Ready Skills:**
- Silicon Valley-relevant tech stack
- AI tool proficiency (hiring requirement)
- Production deployment experience
- Team collaboration
- Professional communication

**Interview Materials:**
- 3 portfolio projects
- GitHub activity
- Technical blog posts
- Demo videos
- System design experience

**Network:**
- Peer connections in AI development
- Instructor relationships
- Industry exposure (guest speakers)
- Northeastern alumni network

**Competitive Advantage:**
- Early adopter of AI tools
- Proven ability to ship
- Portfolio of real applications
- Understanding of AI fundamentals
- Professional practices

---

## 12. PEDAGOGICAL APPROACH

### Learning Philosophy

**Constructivist Approach:**
- Learn by building real projects
- Iterate and improve
- Fail fast, learn faster
- Active experimentation

**Scaffolded Learning:**
- Homeworks build toward projects
- Progressive complexity
- Mastery before advancement
- Support when needed

**Authentic Assessment:**
- Real-world projects
- Production deployments
- Industry practices
- Portfolio-worthy deliverables

### Teaching Methods

**Active Learning:**
- Hands-on coding labs
- Live demonstrations
- Pair programming
- Group discussions
- Code reviews

**Flipped Classroom Elements:**
- Pre-class readings & questions
- In-class labs & workshops
- Office hours for deep dives
- Async resources available

**Formative Assessment:**
- Weekly concept checks
- Pre-class questions
- Lottery (cold calling)
- Homework feedback
- Project check-ins

**Community Building:**
- Slack discussions
- Peer code reviews
- Shared resources
- Collaborative learning
- Demo days

### Cognitive Load Management

**Week 1-5:**
- Foundations & single concepts
- One modality at a time
- Simple projects
- Clear expectations

**Week 6-10:**
- Integration of concepts
- Multiple modalities
- Moderate complexity
- Increased autonomy

**Week 11-15:**
- Advanced techniques
- Team collaboration
- Production practices
- Independence

**Red Flags Addressed:**
- Week 4-5: Spread TDD + CI/CD across two weeks
- Week 9-10: Split evals into two parts
- Week 11: Dedicated team formation
- Throughout: Weekly quizzes for spaced repetition

---

## 13. INSTRUCTOR NOTES

### First Day Agenda

**Hour 1: Course Overview (50 min)**
- Introductions (10 min)
- Course philosophy (10 min)
- Show promotional video (1 min)
- Review syllabus highlights (15 min)
- Demo: Claude Web quick build (10 min)
- Q&A (4 min)

**Break (10 min)**

**Hour 2: LLM Fundamentals (50 min)**
- How transformers work (15 min)
- Tokens & context windows (10 min)
- Hallucinations & limitations (10 min)
- Model comparison demo (10 min)
- Discussion & Q&A (5 min)

**Homework:** Read Mom Test Ch 1-3, submit first pre-class question

### Weekly Routine

**Before Each Class:**
- Review pre-class questions
- Prepare lottery topics
- Test any live demos
- Update Canvas quiz

**During Class:**
- Address top pre-class questions (10 min)
- New content lecture/demo (40 min)
- Break (10 min)
- Hands-on lab/workshop (40 min)

**After Class:**
- Post quiz to Canvas
- Review/respond on Slack
- Grade lottery participation
- Prepare next week

### Project Approval Process

**Students Must:**
1. Post project idea in #projects
2. Include: problem, users, tech stack, timeline
3. Wait for instructor approval
4. Iterate based on feedback

**Instructor Should:**
- Respond within 24 hours
- Ensure appropriate scope
- Check technical feasibility
- Verify learning objectives met
- Approve or request changes

### Grading Strategy

**Timely Feedback:**
- Homeworks: 1 week turnaround
- Projects: 2 week turnaround
- Pre-class: Same day
- Lottery: Real-time

**Rubrics:**
- All rubrics published with assignment
- Self-assessment encouraged
- Example work shown when possible
- Clear expectations

**Partial Credit:**
- Attempt counts
- Process documented
- Learning demonstrated
- Improvement shown

### Common Student Issues

**Issue:** "I don't understand my AI-generated code"
**Response:** Schedule office hours, review together, explain concepts, may need to redo

**Issue:** "AI won't give me what I want"
**Response:** Show prompt engineering techniques, review context, demonstrate iteration

**Issue:** "Project scope too large"
**Response:** Help scope down, identify MVP, create phases, adjust timeline if needed

**Issue:** "Team conflict"
**Response:** Mediate discussion, refer to team contract, adjust roles if necessary, peer eval consequences

**Issue:** "Failed No-AI Challenge"
**Response:** Meeting required, remediation plan, study resources, retake possibility, grade cap

### Teaching Challenges

**AI Tool Evolution:**
- Tools change rapidly
- Stay current with releases
- Update examples as needed
- Flexibility required

**Variable Student Experience:**
- Some never used AI
- Some are power users
- Accommodate both
- Provide resources for all levels

**Balancing Act:**
- Speed vs. Quality
- AI vs. Fundamentals
- Theory vs. Practice
- Individual vs. Team

**Solutions:**
- Clear expectations
- Frequent check-ins
- Flexible support
- Differentiated resources

---

## 14. FUTURE COURSE ITERATIONS

### Feedback Collection

**During Semester:**
- Mid-semester feedback (Week 7-8)
- Weekly informal check-ins
- Office hours conversations
- Slack sentiment

**End of Semester:**
- TRACE evaluations
- Final retrospective
- Exit surveys
- Project showcase feedback

### Potential Improvements

**For Future Offerings:**
- Guest speakers from industry
- Company site visits
- More pair programming
- Additional AI modalities
- Advanced security module
- Performance optimization deep dive
- More real-world case studies

**Curriculum Evolution:**
- Track new AI tools
- Update examples yearly
- Incorporate student feedback
- Add emerging practices
- Adjust project complexity
- Refine homework sequence

### Research Opportunities

**Potential Papers:**
- Pedagogy of AI-assisted learning
- Evaluation of evals effectiveness
- Student outcomes in AI courses
- Best practices for teaching with AI
- No-AI Challenge results analysis

**Data Collection:**
- Project quality metrics
- Time spent on tasks
- AI tool usage patterns
- Student progression
- Learning outcomes

---

## 15. MARKETING & RECRUITMENT

### Target Students

**Ideal Candidates:**
- Master's CS students
- Career switchers to tech
- Working professionals upskilling
- Students interested in startups
- AI-curious developers

**Prerequisites Needed:**
- Programming experience
- Data structures knowledge
- Web development basics
- Git/GitHub familiarity
- Terminal comfort

**Desirable Traits:**
- Curiosity about AI
- Willingness to experiment
- Comfortable with uncertainty
- Self-directed learner
- Career-focused

### Marketing Materials

**Taglines:**
- "Master AI-Assisted Development for Silicon Valley"
- "Build Production Apps with AI â€¢ The Right Way"
- "From Prompts to Production: AI-First Software Engineering"
- "Learn to Code with AI â€¢ Learn to Code Without AI"

**Key Messages:**
1. Only course teaching professional AI workflows
2. Build 3 portfolio-worthy applications
3. Silicon Valley-ready skills
4. Balanced: AI + Fundamentals
5. Future-proof your career

**Promotional Assets:**
- YouTube video: https://www.youtube.com/shorts/GmMXaRY0Z-I
- 5-slide student presentation
- Course website/landing page
- Social media graphics
- Email templates

**Distribution Channels:**
- Northeastern CS department
- Oakland campus announcements
- CS student Slack/Discord
- LinkedIn posts
- Twitter/X
- Reddit (r/cscareerquestions)
- Hacker News (if appropriate)

### Course Positioning

**Unique Selling Points:**
1. **Inaugural Offering** - Be part of first cohort
2. **Cutting-Edge** - Learn 2026 practices
3. **Portfolio-Focused** - Job-ready deliverables
4. **Comprehensive** - AI + Professional practices
5. **Small Class** - Personalized attention

**Competitive Advantage:**
- No other course teaches this comprehensively
- Industry-relevant immediately
- Professor expertise in both AI and teaching
- Oakland campus location (tech hub)
- Northeastern reputation

---

## 16. RESOURCES & REFERENCES

### Course Development

**Expert Feedback Incorporated:**
- Senior Software Engineer (FAANG, 10+ years)
- CS Professor (20+ years teaching)
- AI Expert & Educator (5+ years)

**Key Improvements Made:**
1. Added LLM Fundamentals (Week 1)
2. Reduced cognitive overload (spread content)
3. Added formative assessments (weekly quizzes)
4. Created detailed project rubrics
5. Added No-AI Challenge
6. Improved scaffolding (early weeks)
7. Expanded evals methodology

**Research Consulted:**
- Vibe coding industry trends (Y Combinator data)
- AI tool adoption in tech companies
- Pedagogical best practices
- Cognitive load research
- Assessment design theory

### Additional Reading

**For Instructor:**
- "Attention Is All You Need" (Transformer paper)
- Anthropic's prompt engineering guide
- Antigravity best practices documentation
- Research on AI in education
- Agile methodology references

**For Students (Optional):**
- "The Pragmatic Programmer"
- "Clean Code" by Robert Martin
- "Designing Data-Intensive Applications"
- AI tool documentation sites
- Tech blogs (Medium, Dev.to)

### Community Resources

**External Communities:**
- Antigravity Community Discord
- Anthropic Claude community
- r/ChatGPT, r/ClaudeAI
- AI coding Twitter/X
- Local tech meetups

**Course-Specific:**
- Class Slack workspace
- GitHub organization
- Shared Notion/wiki
- Resource library
- Alumni network

---

## 17. VERSION HISTORY

### v1.0 - January 8, 2025
- Initial comprehensive course plan
- 15-week curriculum defined
- 3 projects + 6 homeworks specified
- All rubrics created
- Weekly schedule finalized
- Expert feedback incorporated
- No-AI Challenge added
- LLM Fundamentals module added
- Reduced from 4 to 3 modalities
- Lottery changed to 10%
- All materials ready for Spring 2026

### Future Versions
Track changes semester-to-semester:
- Student feedback integration
- Tool updates
- Industry trend shifts
- Pedagogical improvements
- New features/techniques

---

## 18. QUICK REFERENCE

### Important Links
- **Promotional Video:** https://www.youtube.com/shorts/GmMXaRY0Z-I
- **Google Drive Folder:** https://drive.google.com/drive/folders/1RaCcAgGNhPUDfrRt6_U4xdYX-T2C88gh
- **Instructor Email:** jguerra@northeastern.edu
- **Course Code:** CS 7180

### Key Dates (Spring 2026)
- **Week 1:** Course start, LLM Fundamentals
- **Week 2:** HW1 due (Mom Test)
- **Week 3:** HW2 due (Prompt Engineering)
- **Week 6:** Project 1 due + demos
- **Week 7:** HW3 due (Context Engineering)
- **Week 10:** HW4 due + No-AI Challenge + Project 2 almost due
- **Week 11:** Project 2 due + demos
- **Week 12:** HW5 due (Parallel Agents)
- **Week 13:** HW6 due (Production Readiness)
- **Week 15:** Project 3 due + Demo Day

### Assessment Summary
| Component | Weight | Count |
|-----------|--------|-------|
| Participation | 20% | Weekly (pre-class + lottery + quizzes) |
| Homeworks | 25% | 6 assignments |
| Projects | 55% | 3 projects |
| No-AI Challenge | Pass/Fail | 1 midterm (must pass 60%) |

### Contact Methods
1. **Slack** - Quick questions, community
2. **Office Hours** - Deep discussions, help
3. **Email** - Formal communications
4. **Canvas** - Submissions, grades

---

## 19. SUCCESS METRICS

### For Students

**By End of Course:**
- 3 deployed applications
- Professional GitHub profile
- Technical blog posts
- Strong AI tool proficiency
- TDD/CI/CD experience
- Job interview materials

**Key Performance Indicators:**
- All projects deployed
- 80%+ test coverage (P2, P3)
- Pass No-AI Challenge
- Active Slack participation
- Consistent homework completion

### For Course

**Success Indicators:**
- Student satisfaction (TRACE >4.0/5.0)
- Job placement rate
- Portfolio quality
- Student engagement
- Completion rate

**Assessment Data:**
- Average project grades
- No-AI Challenge pass rate
- Homework completion rate
- Participation levels
- Tool adoption

**Qualitative Feedback:**
- Student testimonials
- Employer feedback
- Alumni success stories
- Industry relevance
- Peer instructor interest

---

## 20. CLOSING NOTES

### Course Philosophy Summary

This course exists because:
1. **AI is transforming software development NOW**
2. **Universities need to teach current practices**
3. **Students need practical, job-ready skills**
4. **AI augments developers, doesn't replace them**
5. **Professional standards still matter**

The balance of AI-assisted speed with engineering quality prepares students for the reality of 2026 software development.

### Instructor Commitment

**I commit to:**
- Stay current with AI tools
- Provide timely, helpful feedback
- Be available for student support
- Create engaging, relevant content
- Foster inclusive community
- Continuously improve course
- Celebrate student success

### Student Expectations

**I expect students to:**
- Engage actively
- Experiment freely
- Learn from failures
- Support each other
- Take ownership
- Build impressive projects
- Embrace uncertainty
- Ask for help

### Final Thoughts

This is a new kind of course for a new era of software development. We're building this together. Your feedback, questions, challenges, and successes will shape not just this course but how we teach AI-assisted development going forward.

**Let's build something amazing! ðŸš€**

---

**END OF PROJECT MEMORY**

---

## Appendix: File Inventory

**Core Documents:**
- CS7180_VibeCoding_Syllabus.docx
- CS7180_VibeCoding_Syllabus.md
- CS7180_Project_Memory.md (this file)
- landing-page-context.md
- CS7180_Presentation_Guide.md
- drive-organization-guide.md

**Location:**
Google Drive: /2026/NU/Spring2026_VibeCoding/

**Status:** All materials complete and ready for Spring 2026 launch
